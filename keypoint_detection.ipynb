{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facial Keypoint Detection\n",
    "This notebook implements facial keypoint detection (68 landmarks) using four approaches:\n",
    "1. **CNN** — Custom convolutional network (regression)\n",
    "2. **ResNet** — Transfer learning with ResNet18 (regression)\n",
    "3. **DINO** — Transfer learning with DINO Vision Transformer (regression)\n",
    "4. **U-Net** — Heatmap-based keypoint detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import subprocess\n",
    "import zipfile\n",
    "\n",
    "import cv2\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import wandb\n",
    "from PIL import Image\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import models, transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data(data_dir='data'):\n",
    "    if os.path.exists(os.path.join(data_dir, 'training')) and os.path.exists(os.path.join(data_dir, 'test')):\n",
    "        print(\"Data already exists.\")\n",
    "        return\n",
    "    print(\"Data not found. Downloading...\")\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "    zip_path = os.path.join(data_dir, 'train-test-data.zip')\n",
    "    subprocess.run([\n",
    "        'wget', '-q', '-O', zip_path,\n",
    "        'https://s3.amazonaws.com/video.udacity-data.com/topher/2018/May/5aea1b91_train-test-data/train-test-data.zip'\n",
    "    ], check=True)\n",
    "    with zipfile.ZipFile(zip_path, 'r') as z:\n",
    "        z.extractall(data_dir)\n",
    "    os.remove(zip_path)\n",
    "    print(\"Data downloaded and extracted.\")\n",
    "\n",
    "download_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rescale:\n",
    "    \"\"\"Rescale the image in a sample to a given size.\"\"\"\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, key_pts = sample['image'], sample['keypoints']\n",
    "        h, w = image.shape[:2]\n",
    "        if isinstance(self.output_size, int):\n",
    "            if h > w:\n",
    "                new_h, new_w = self.output_size * h / w, self.output_size\n",
    "            else:\n",
    "                new_h, new_w = self.output_size, self.output_size * w / h\n",
    "        else:\n",
    "            new_h, new_w = self.output_size\n",
    "        new_h, new_w = int(new_h), int(new_w)\n",
    "        img = cv2.resize(image, (new_w, new_h))\n",
    "        key_pts = key_pts * [new_w / w, new_h / h]\n",
    "        return {'image': img, 'keypoints': key_pts}\n",
    "\n",
    "\n",
    "class RandomCrop:\n",
    "    \"\"\"Crop randomly the image in a sample.\"\"\"\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        if isinstance(output_size, int):\n",
    "            self.output_size = (output_size, output_size)\n",
    "        else:\n",
    "            self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, key_pts = sample['image'], sample['keypoints']\n",
    "        h, w = image.shape[:2]\n",
    "        new_h, new_w = self.output_size\n",
    "        top = np.random.randint(0, h - new_h)\n",
    "        left = np.random.randint(0, w - new_w)\n",
    "        image = image[top:top + new_h, left:left + new_w]\n",
    "        key_pts = key_pts - [left, top]\n",
    "        return {'image': image, 'keypoints': key_pts}\n",
    "\n",
    "\n",
    "class NormalizeOriginal:\n",
    "    \"\"\"Convert to grayscale and normalize image [0,1], keypoints (pts-100)/50.\"\"\"\n",
    "    def __call__(self, sample):\n",
    "        image, key_pts = sample['image'], sample['keypoints']\n",
    "        image_copy = cv2.cvtColor(np.copy(image), cv2.COLOR_RGB2GRAY)\n",
    "        image_copy = (image_copy / 255.0).astype(np.float32)\n",
    "        key_pts_copy = (np.copy(key_pts) - 100) / 50.0\n",
    "        return {'image': image_copy, 'keypoints': key_pts_copy}\n",
    "\n",
    "\n",
    "class ToTensor:\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "    def __call__(self, sample):\n",
    "        image, key_pts = sample['image'], sample['keypoints']\n",
    "        if len(image.shape) == 2:\n",
    "            image = image.reshape(image.shape[0], image.shape[1], 1)\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        return {'image': torch.from_numpy(image), 'keypoints': torch.from_numpy(key_pts)}\n",
    "\n",
    "\n",
    "class RandomHorizontalFlip:\n",
    "    \"\"\"Random horizontal flip with correct keypoint mirroring for 68 landmarks.\"\"\"\n",
    "    def __call__(self, sample):\n",
    "        image, key_pts = sample['image'], sample['keypoints']\n",
    "        image_copy = np.copy(image)\n",
    "        key_pts_copy = np.copy(key_pts)\n",
    "        key_pts_copy_2 = np.copy(key_pts_copy)\n",
    "\n",
    "        if random.choice([0, 1]) <= 0.5:\n",
    "            image_copy = np.fliplr(image_copy)\n",
    "            key_pts_copy[:, 0] = -key_pts_copy[:, 0]\n",
    "            key_pts_copy[:, 0] = key_pts_copy[:, 0] + image_copy.shape[1]\n",
    "            key_pts_copy_2 = np.copy(key_pts_copy)\n",
    "\n",
    "            # Mirror jawline\n",
    "            for i, j in zip(range(0, 8), range(16, 8, -1)):\n",
    "                key_pts_copy_2[j] = key_pts_copy[i]\n",
    "                key_pts_copy_2[i] = key_pts_copy[j]\n",
    "            # Mirror eyebrows\n",
    "            for i, j in zip(range(17, 22), range(26, 21, -1)):\n",
    "                key_pts_copy_2[j] = key_pts_copy[i]\n",
    "                key_pts_copy_2[i] = key_pts_copy[j]\n",
    "            # Mirror nose tip\n",
    "            key_pts_copy_2[35] = key_pts_copy[31]\n",
    "            key_pts_copy_2[34] = key_pts_copy[32]\n",
    "            key_pts_copy_2[32] = key_pts_copy[34]\n",
    "            key_pts_copy_2[31] = key_pts_copy[35]\n",
    "            # Mirror eyes\n",
    "            key_pts_copy_2[45] = key_pts_copy[36]; key_pts_copy_2[44] = key_pts_copy[37]\n",
    "            key_pts_copy_2[43] = key_pts_copy[38]; key_pts_copy_2[42] = key_pts_copy[39]\n",
    "            key_pts_copy_2[47] = key_pts_copy[40]; key_pts_copy_2[46] = key_pts_copy[41]\n",
    "            key_pts_copy_2[39] = key_pts_copy[42]; key_pts_copy_2[38] = key_pts_copy[43]\n",
    "            key_pts_copy_2[37] = key_pts_copy[44]; key_pts_copy_2[36] = key_pts_copy[45]\n",
    "            key_pts_copy_2[41] = key_pts_copy[46]; key_pts_copy_2[40] = key_pts_copy[47]\n",
    "            # Mirror lips\n",
    "            key_pts_copy_2[54] = key_pts_copy[48]; key_pts_copy_2[53] = key_pts_copy[49]\n",
    "            key_pts_copy_2[52] = key_pts_copy[50]; key_pts_copy_2[50] = key_pts_copy[52]\n",
    "            key_pts_copy_2[49] = key_pts_copy[53]; key_pts_copy_2[48] = key_pts_copy[54]\n",
    "            key_pts_copy_2[59] = key_pts_copy[55]; key_pts_copy_2[58] = key_pts_copy[56]\n",
    "            key_pts_copy_2[56] = key_pts_copy[58]; key_pts_copy_2[55] = key_pts_copy[59]\n",
    "            key_pts_copy_2[64] = key_pts_copy[60]; key_pts_copy_2[63] = key_pts_copy[61]\n",
    "            key_pts_copy_2[61] = key_pts_copy[63]; key_pts_copy_2[60] = key_pts_copy[64]\n",
    "            key_pts_copy_2[67] = key_pts_copy[65]; key_pts_copy_2[65] = key_pts_copy[67]\n",
    "\n",
    "        return {'image': image_copy, 'keypoints': key_pts_copy_2}\n",
    "\n",
    "\n",
    "class RandomRotate:\n",
    "    \"\"\"Random rotation by +/- angle degrees.\"\"\"\n",
    "    def __init__(self, rotation=30):\n",
    "        self.rotation = rotation\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, key_pts = sample['image'], sample['keypoints']\n",
    "        image_copy = np.copy(image)\n",
    "        key_pts_copy = np.copy(key_pts)\n",
    "        rows, cols = image.shape[:2]\n",
    "        M = cv2.getRotationMatrix2D((rows / 2, cols / 2), random.choice([-self.rotation, self.rotation]), 1)\n",
    "        image_copy = cv2.warpAffine(image_copy, M, (cols, rows))\n",
    "        key_pts_copy = key_pts_copy.reshape((1, 136))\n",
    "        new_keypoints = np.zeros(136)\n",
    "        for i in range(68):\n",
    "            coord_idx = 2 * i\n",
    "            old_coord = key_pts_copy[0][coord_idx:coord_idx + 2]\n",
    "            new_coord = np.matmul(M, np.append(old_coord, 1))\n",
    "            new_keypoints[coord_idx] += new_coord[0]\n",
    "            new_keypoints[coord_idx + 1] += new_coord[1]\n",
    "        return {'image': image_copy, 'keypoints': new_keypoints.reshape((68, 2))}\n",
    "\n",
    "\n",
    "class ColorJitter:\n",
    "    \"\"\"Random color jitter (brightness, contrast, saturation).\"\"\"\n",
    "    def __call__(self, sample):\n",
    "        image, key_pts = sample['image'], sample['keypoints']\n",
    "        color_jitter = transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4)\n",
    "        image_copy = np.copy(image)\n",
    "        if image_copy.dtype != np.uint8:\n",
    "            image_copy = (image_copy * 255).astype(np.uint8)\n",
    "        image_copy = np.array(color_jitter(Image.fromarray(image_copy)))\n",
    "        return {'image': image_copy, 'keypoints': np.copy(key_pts)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FacialKeypointsDataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset for regression-based models.\"\"\"\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.key_pts_frame = pd.read_csv(csv_file, index_col=0)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.key_pts_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_name = os.path.join(self.root_dir, self.key_pts_frame.index[idx])\n",
    "        image = mpimg.imread(image_name)\n",
    "        if image.shape[2] == 4:\n",
    "            image = image[:, :, 0:3]\n",
    "        key_pts = self.key_pts_frame.iloc[idx, :].values.astype('float').reshape(-1, 2)\n",
    "        sample = {'image': image, 'keypoints': key_pts}\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample\n",
    "\n",
    "\n",
    "class FacialKeypointsHeatmapDataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset with heatmap generation for U-Net.\"\"\"\n",
    "    def __init__(self, csv_file, root_dir, transform=None, output_size=64, sigma=1, image_size=224):\n",
    "        self.key_pts_frame = pd.read_csv(csv_file, index_col=0)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.output_size = output_size\n",
    "        self.sigma = sigma\n",
    "        self.image_size = image_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.key_pts_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_name = os.path.join(self.root_dir, self.key_pts_frame.index[idx])\n",
    "        image = mpimg.imread(image_name)\n",
    "        if image.shape[2] == 4:\n",
    "            image = image[:, :, 0:3]\n",
    "        key_pts = self.key_pts_frame.iloc[idx, :].values.astype('float').reshape(-1, 2)\n",
    "        sample = {'image': image, 'keypoints': key_pts}\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        sample['heatmaps'] = self.generate_heatmaps(sample['keypoints'])\n",
    "        return sample\n",
    "\n",
    "    def generate_heatmaps(self, keypoints):\n",
    "        if isinstance(keypoints, torch.Tensor):\n",
    "            keypoints = keypoints.numpy()\n",
    "        num_keypoints = keypoints.shape[0]\n",
    "        heatmaps = np.zeros((num_keypoints, self.output_size, self.output_size), dtype=np.float32)\n",
    "        keypoints_scaled = (keypoints * 50 + 100) * (self.output_size / self.image_size)\n",
    "        for i in range(num_keypoints):\n",
    "            x, y = keypoints_scaled[i]\n",
    "            if np.isnan(x) or np.isnan(y):\n",
    "                continue\n",
    "            x_int = max(0, min(self.output_size - 1, int(x)))\n",
    "            y_int = max(0, min(self.output_size - 1, int(y)))\n",
    "            heatmap = np.zeros((self.output_size, self.output_size), dtype=np.float32)\n",
    "            heatmap[y_int, x_int] = 1.0\n",
    "            heatmap = gaussian_filter(heatmap, sigma=self.sigma)\n",
    "            if heatmap.max() > 0:\n",
    "                heatmap = heatmap / heatmap.max()\n",
    "            heatmaps[i] = heatmap\n",
    "        return torch.from_numpy(heatmaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_regression_data(batch_size=64):\n",
    "    \"\"\"Load datasets and dataloaders for regression-based models (CNN, ResNet, DINO).\"\"\"\n",
    "    data_transform = transforms.Compose([\n",
    "        Rescale(250), RandomCrop(224), NormalizeOriginal(), ToTensor()\n",
    "    ])\n",
    "    train_dataset = FacialKeypointsDataset('data/training_frames_keypoints.csv', 'data/training', data_transform)\n",
    "    test_dataset = FacialKeypointsDataset('data/test_frames_keypoints.csv', 'data/test', data_transform)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "def load_heatmap_data(batch_size=256, heatmap_size=64):\n",
    "    \"\"\"Load datasets and dataloaders for heatmap-based models (U-Net).\"\"\"\n",
    "    train_transform = transforms.Compose([\n",
    "        Rescale(250), RandomCrop(224), RandomHorizontalFlip(), RandomRotate(15),\n",
    "        ColorJitter(), NormalizeOriginal(), ToTensor()\n",
    "    ])\n",
    "    test_transform = transforms.Compose([\n",
    "        Rescale((224, 224)), NormalizeOriginal(), ToTensor()\n",
    "    ])\n",
    "    train_dataset = FacialKeypointsHeatmapDataset(\n",
    "        'data/training_frames_keypoints.csv', 'data/training',\n",
    "        transform=train_transform, output_size=heatmap_size, sigma=2, image_size=224)\n",
    "    test_dataset = FacialKeypointsHeatmapDataset(\n",
    "        'data/test_frames_keypoints.csv', 'data/test',\n",
    "        transform=test_transform, output_size=heatmap_size, sigma=2, image_size=224)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Training & Evaluation Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(model, optimizer, epoch, step, model_name, path='checkpoints/last_checkpoint.pth'):\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'epoch': epoch, 'step': step, 'model_name': model_name,\n",
    "    }, path)\n",
    "    print(f\"Checkpoint saved to {path}\")\n",
    "\n",
    "\n",
    "def evaluate_regression(model, test_loader, criterion, device):\n",
    "    \"\"\"Evaluate a regression model (CNN/ResNet/DINO) on the test set.\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            images = batch['image'].to(device)\n",
    "            keypoints = batch['keypoints'].view(images.size(0), -1).to(device)\n",
    "            outputs = model(images)\n",
    "            loss = model.compute_loss(outputs, keypoints, criterion)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(test_loader)\n",
    "\n",
    "\n",
    "def evaluate_heatmap(model, test_loader, device):\n",
    "    \"\"\"Evaluate U-Net on the test set using BCE loss.\"\"\"\n",
    "    model.eval()\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([10.0]).to(device))\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            images = batch['image'].to(device)\n",
    "            target = batch['heatmaps'].to(device)\n",
    "            logits = model(images)\n",
    "            total_loss += criterion(logits, target).item()\n",
    "    return total_loss / len(test_loader)\n",
    "\n",
    "\n",
    "def heatmaps_to_keypoints(heatmaps, heatmap_size=64, image_size=224):\n",
    "    \"\"\"Extract keypoint coordinates from heatmaps using argmax.\"\"\"\n",
    "    batch_size, num_kpts, h, w = heatmaps.shape\n",
    "    heatmaps_flat = heatmaps.view(batch_size, num_kpts, -1)\n",
    "    max_indices = heatmaps_flat.argmax(dim=2)\n",
    "    y_coords = (max_indices // w).float()\n",
    "    x_coords = (max_indices % w).float()\n",
    "    x_coords = x_coords * (image_size / heatmap_size)\n",
    "    y_coords = y_coords * (image_size / heatmap_size)\n",
    "    x_norm = (x_coords - 100) / 50.0\n",
    "    y_norm = (y_coords - 100) / 50.0\n",
    "    return torch.stack([x_norm, y_norm], dim=2)\n",
    "\n",
    "\n",
    "def train_regression(model, train_loader, test_loader, optimizer, criterion, device,\n",
    "                     model_name='model', num_epochs=10, eval_interval=10,\n",
    "                     log_interval=5, save_interval=30):\n",
    "    \"\"\"Training loop for regression-based models (CNN, ResNet, DINO).\"\"\"\n",
    "    step = 0\n",
    "    running_loss = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            step += 1\n",
    "            image = batch['image'].to(device)\n",
    "            keypoints = batch['keypoints'].reshape(image.size(0), 136).float().to(device)\n",
    "\n",
    "            preds = model(image)\n",
    "            loss = model.compute_loss(preds, keypoints, criterion)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            if step % log_interval == 0:\n",
    "                avg_loss = running_loss / log_interval\n",
    "                wandb.log({'train_loss': avg_loss, 'step': step})\n",
    "                print(f\"Step {step}: Train Loss = {avg_loss:.4f}\")\n",
    "                running_loss = 0\n",
    "\n",
    "            if step % eval_interval == 0:\n",
    "                val_loss = evaluate_regression(model, test_loader, criterion, device)\n",
    "                wandb.log({'val_loss': val_loss, 'step': step})\n",
    "                model.train()\n",
    "\n",
    "            if step % save_interval == 0:\n",
    "                save_checkpoint(model, optimizer, epoch, step, model_name,\n",
    "                                path=f'checkpoints-{model_name}/step_{step}.pth')\n",
    "\n",
    "    print(f\"Training complete for {model_name}!\")\n",
    "    return epoch, step\n",
    "\n",
    "\n",
    "def train_heatmap(model, train_loader, test_loader, optimizer, device,\n",
    "                  model_name='unet', num_epochs=10, eval_interval=10,\n",
    "                  log_interval=5, save_interval=30):\n",
    "    \"\"\"Training loop for heatmap-based models (U-Net).\"\"\"\n",
    "    step = 0\n",
    "    running_loss = 0\n",
    "    best_val_loss = float('inf')\n",
    "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([10.0]).to(device))\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            step += 1\n",
    "            images = batch['image'].to(device)\n",
    "            heatmaps_gt = batch['heatmaps'].to(device)\n",
    "\n",
    "            logits = model(images)\n",
    "            loss = criterion(logits, heatmaps_gt)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            if step % log_interval == 0:\n",
    "                avg_loss = running_loss / log_interval\n",
    "                wandb.log({'train_loss': avg_loss, 'step': step, 'epoch': epoch,\n",
    "                           'lr': optimizer.param_groups[0]['lr']})\n",
    "                print(f\"Epoch {epoch}, Step {step}: Train Loss = {avg_loss:.6f} (lr={optimizer.param_groups[0]['lr']:.6f})\")\n",
    "                running_loss = 0\n",
    "\n",
    "            if step % eval_interval == 0:\n",
    "                val_loss = evaluate_heatmap(model, test_loader, device)\n",
    "                wandb.log({'val_loss': val_loss, 'step': step, 'epoch': epoch})\n",
    "                print(f\"Epoch {epoch}, Step {step}: Val Loss = {val_loss:.6f}\")\n",
    "                model.train()\n",
    "                if val_loss < best_val_loss:\n",
    "                    best_val_loss = val_loss\n",
    "                    save_checkpoint(model, optimizer, epoch, step, model_name,\n",
    "                                    path=f'checkpoints-{model_name}/best.pth')\n",
    "                    print(f\"  -> New best val loss: {val_loss:.6f}\")\n",
    "\n",
    "            if step % save_interval == 0:\n",
    "                save_checkpoint(model, optimizer, epoch, step, model_name,\n",
    "                                path=f'checkpoints-{model_name}/step_{step}.pth')\n",
    "\n",
    "        epoch_val_loss = evaluate_heatmap(model, test_loader, device)\n",
    "        scheduler.step(epoch_val_loss)\n",
    "        print(f\"--- Epoch {epoch} done. Val Loss = {epoch_val_loss:.6f}, LR = {optimizer.param_groups[0]['lr']:.6f} ---\")\n",
    "        model.train()\n",
    "\n",
    "    print(\"Heatmap training complete!\")\n",
    "    return epoch, step\n",
    "\n",
    "\n",
    "def visualize_keypoints(test_loader, model, device='cuda'):\n",
    "    \"\"\"Visualize predicted vs ground-truth keypoints on test samples.\"\"\"\n",
    "    model.eval()\n",
    "    for i, data in enumerate(test_loader):\n",
    "        image = data['image'][0]\n",
    "        images = data['image']\n",
    "        with torch.no_grad():\n",
    "            images = images.to(device)\n",
    "            predictions = model(images)\n",
    "        if predictions.dim() == 4:\n",
    "            predictions = heatmaps_to_keypoints(predictions)\n",
    "        else:\n",
    "            predictions = predictions.reshape(images.size(0), 68, 2)\n",
    "        predictions = predictions.cpu().numpy()\n",
    "        pred_kpts = predictions[0]\n",
    "        gt_kpts = data['keypoints'][0].numpy()\n",
    "        pred_kpts_denorm = (pred_kpts * 50) + 100\n",
    "        gt_kpts_denorm = (gt_kpts * 50) + 100\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.imshow(image.numpy().transpose(1, 2, 0), cmap='gray')\n",
    "        plt.scatter(pred_kpts_denorm[:, 0], pred_kpts_denorm[:, 1], c='r', s=20, label='Predicted')\n",
    "        plt.scatter(gt_kpts_denorm[:, 0], gt_kpts_denorm[:, 1], c='g', s=20, label='Ground Truth')\n",
    "        plt.legend()\n",
    "        plt.title(f'Test Sample {i}')\n",
    "        plt.show()\n",
    "        if i >= 4:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_keypoints=68, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        self.fc1 = nn.Linear(256 * 14 * 14, 512)\n",
    "        self.fc2 = nn.Linear(512, num_keypoints * 2)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.bn1(self.conv1(x))), 2)\n",
    "        x = F.max_pool2d(F.relu(self.bn2(self.conv2(x))), 2)\n",
    "        x = F.max_pool2d(F.relu(self.bn3(self.conv3(x))), 2)\n",
    "        x = F.max_pool2d(F.relu(self.bn4(self.conv4(x))), 2)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        return self.fc2(x)\n",
    "\n",
    "    def compute_loss(self, preds, labels, criterion):\n",
    "        if criterion == 'mse':\n",
    "            loss_fn = nn.MSELoss()\n",
    "        elif criterion == 'Smoothl1Loss':\n",
    "            loss_fn = nn.SmoothL1Loss()\n",
    "        else:\n",
    "            raise ValueError(f'Unknown criterion: {criterion}')\n",
    "        return loss_fn(preds, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Train CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "CNN_EPOCHS = 50\n",
    "CNN_CRITERION = 'Smoothl1Loss'  # or 'mse'\n",
    "CNN_LR = 1e-3\n",
    "CNN_BATCH_SIZE = 64\n",
    "\n",
    "# --- Initialize ---\n",
    "cnn_model = CNN().to(device)\n",
    "cnn_train_loader, cnn_test_loader = load_regression_data(batch_size=CNN_BATCH_SIZE)\n",
    "cnn_optimizer = torch.optim.Adam(cnn_model.parameters(), lr=CNN_LR)\n",
    "\n",
    "print(f\"CNN parameters: {sum(p.numel() for p in cnn_model.parameters()):,}\")\n",
    "\n",
    "# --- Train ---\n",
    "wandb.init(project='facial-keypoints', name='cnn-train', reinit=True)\n",
    "wandb.config.update({'model': 'cnn', 'criterion': CNN_CRITERION, 'lr': CNN_LR})\n",
    "\n",
    "cnn_epoch, cnn_step = train_regression(\n",
    "    cnn_model, cnn_train_loader, cnn_test_loader, cnn_optimizer,\n",
    "    CNN_CRITERION, device, model_name='cnn', num_epochs=CNN_EPOCHS\n",
    ")\n",
    "\n",
    "save_checkpoint(cnn_model, cnn_optimizer, cnn_epoch, cnn_step, 'cnn',\n",
    "                path='checkpoints-cnn/last_checkpoint.pth')\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Visualize CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_keypoints(cnn_test_loader, cnn_model, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 ResNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetKeypointDetector(nn.Module):\n",
    "    def __init__(self, num_keypoints=68, backbone='resnet18', pretrained=True, freeze_backbone=True):\n",
    "        super().__init__()\n",
    "        if backbone == 'resnet18':\n",
    "            self.backbone = models.resnet18(pretrained=pretrained)\n",
    "        elif backbone == 'resnet34':\n",
    "            self.backbone = models.resnet34(pretrained=pretrained)\n",
    "\n",
    "        # Adapt first conv for grayscale\n",
    "        original_conv = self.backbone.conv1\n",
    "        self.backbone.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        if pretrained:\n",
    "            with torch.no_grad():\n",
    "                self.backbone.conv1.weight[:, 0, :, :] = original_conv.weight[:, 0, :, :]\n",
    "\n",
    "        self.backbone_out_features = self.backbone.fc.in_features\n",
    "        self.backbone.fc = nn.Identity()\n",
    "\n",
    "        self.regression_head = nn.Sequential(\n",
    "            nn.Linear(self.backbone_out_features, 1024), nn.ReLU(), nn.Dropout(0.5),\n",
    "            nn.Linear(1024, 512), nn.ReLU(), nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_keypoints * 2),\n",
    "        )\n",
    "\n",
    "        self.freeze_backbone = freeze_backbone\n",
    "        if freeze_backbone:\n",
    "            self._freeze_backbone()\n",
    "\n",
    "    def _freeze_backbone(self):\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def _unfreeze_backbone(self):\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        return self.regression_head(features)\n",
    "\n",
    "    def compute_loss(self, preds, labels, criterion):\n",
    "        if criterion == 'mse':\n",
    "            loss_fn = nn.MSELoss()\n",
    "        elif criterion == 'Smoothl1Loss':\n",
    "            loss_fn = nn.SmoothL1Loss()\n",
    "        else:\n",
    "            raise ValueError(f'Unknown criterion: {criterion}')\n",
    "        return loss_fn(preds, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Train ResNet (Stage 1: Frozen Backbone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "RESNET_EPOCHS_FROZEN = 50\n",
    "RESNET_CRITERION = 'Smoothl1Loss'\n",
    "RESNET_LR_FROZEN = 5e-4\n",
    "RESNET_BATCH_SIZE = 64\n",
    "\n",
    "# --- Initialize ---\n",
    "resnet_model = ResNetKeypointDetector(backbone='resnet18', pretrained=True, freeze_backbone=True).to(device)\n",
    "resnet_train_loader, resnet_test_loader = load_regression_data(batch_size=RESNET_BATCH_SIZE)\n",
    "resnet_optimizer = torch.optim.Adam(\n",
    "    [p for p in resnet_model.parameters() if p.requires_grad], lr=RESNET_LR_FROZEN\n",
    ")\n",
    "\n",
    "print(f\"ResNet parameters (total): {sum(p.numel() for p in resnet_model.parameters()):,}\")\n",
    "print(f\"ResNet parameters (trainable): {sum(p.numel() for p in resnet_model.parameters() if p.requires_grad):,}\")\n",
    "\n",
    "# --- Train Stage 1: Frozen backbone ---\n",
    "wandb.init(project='facial-keypoints', name='resnet-frozen', reinit=True)\n",
    "wandb.config.update({'model': 'resnet', 'criterion': RESNET_CRITERION, 'freeze': True})\n",
    "\n",
    "resnet_epoch, resnet_step = train_regression(\n",
    "    resnet_model, resnet_train_loader, resnet_test_loader, resnet_optimizer,\n",
    "    RESNET_CRITERION, device, model_name='resnet', num_epochs=RESNET_EPOCHS_FROZEN\n",
    ")\n",
    "\n",
    "save_checkpoint(resnet_model, resnet_optimizer, resnet_epoch, resnet_step, 'resnet',\n",
    "                path='checkpoints-resnet/frozen_checkpoint.pth')\n",
    "wandb.finish()\n",
    "print(\"Stage 1 (frozen backbone) complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Train ResNet (Stage 2: Fine-tune Full Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "RESNET_EPOCHS_FINETUNE = 50\n",
    "RESNET_LR_FINETUNE = 1e-4\n",
    "\n",
    "# --- Unfreeze and set up new optimizer ---\n",
    "resnet_model._unfreeze_backbone()\n",
    "resnet_optimizer = torch.optim.Adam(resnet_model.parameters(), lr=RESNET_LR_FINETUNE)\n",
    "\n",
    "print(f\"ResNet parameters (trainable after unfreeze): {sum(p.numel() for p in resnet_model.parameters() if p.requires_grad):,}\")\n",
    "\n",
    "# --- Train Stage 2: Fine-tune ---\n",
    "wandb.init(project='facial-keypoints', name='resnet-finetune', reinit=True)\n",
    "wandb.config.update({'model': 'resnet', 'criterion': RESNET_CRITERION, 'freeze': False})\n",
    "\n",
    "resnet_epoch, resnet_step = train_regression(\n",
    "    resnet_model, resnet_train_loader, resnet_test_loader, resnet_optimizer,\n",
    "    RESNET_CRITERION, device, model_name='resnet', num_epochs=RESNET_EPOCHS_FINETUNE\n",
    ")\n",
    "\n",
    "save_checkpoint(resnet_model, resnet_optimizer, resnet_epoch, resnet_step, 'resnet',\n",
    "                path='checkpoints-resnet/last_checkpoint.pth')\n",
    "wandb.finish()\n",
    "print(\"Stage 2 (fine-tune) complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Visualize ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_keypoints(resnet_test_loader, resnet_model, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 DINO Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DINOKeypointDetector(nn.Module):\n",
    "    def __init__(self, num_keypoints=68, model_name='vit_base_patch16_224.dino',\n",
    "                 pretrained=True, freeze_backbone=True):\n",
    "        super().__init__()\n",
    "        self.backbone = timm.create_model(model_name, pretrained=pretrained)\n",
    "        self.backbone_out_features = self.backbone.embed_dim\n",
    "        self.backbone.head = nn.Identity()\n",
    "\n",
    "        self.regression_head = nn.Sequential(\n",
    "            nn.Linear(self.backbone_out_features, 1024), nn.ReLU(), nn.Dropout(0.5),\n",
    "            nn.Linear(1024, 512), nn.ReLU(), nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_keypoints * 2),\n",
    "        )\n",
    "\n",
    "        self.freeze_backbone = freeze_backbone\n",
    "        if freeze_backbone:\n",
    "            self._freeze_backbone()\n",
    "\n",
    "    def _freeze_backbone(self):\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def _unfreeze_backbone(self):\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x.size(1) == 1:\n",
    "            x = x.repeat(1, 3, 1, 1)\n",
    "        features = self.backbone.forward_features(x)\n",
    "        if len(features.shape) > 2:\n",
    "            features = features[:, 0, :]\n",
    "        return self.regression_head(features)\n",
    "\n",
    "    def compute_loss(self, preds, labels, criterion):\n",
    "        if criterion == 'mse':\n",
    "            loss_fn = nn.MSELoss()\n",
    "        elif criterion == 'Smoothl1Loss':\n",
    "            loss_fn = nn.SmoothL1Loss()\n",
    "        else:\n",
    "            raise ValueError(f'Unknown criterion: {criterion}')\n",
    "        return loss_fn(preds, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Train DINO (Stage 1: Frozen Backbone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "DINO_EPOCHS_FROZEN = 50\n",
    "DINO_CRITERION = 'Smoothl1Loss'\n",
    "DINO_LR_FROZEN = 5e-4\n",
    "DINO_BATCH_SIZE = 64\n",
    "\n",
    "# --- Initialize ---\n",
    "dino_model = DINOKeypointDetector(pretrained=True, freeze_backbone=True).to(device)\n",
    "dino_train_loader, dino_test_loader = load_regression_data(batch_size=DINO_BATCH_SIZE)\n",
    "dino_optimizer = torch.optim.Adam(\n",
    "    [p for p in dino_model.parameters() if p.requires_grad], lr=DINO_LR_FROZEN\n",
    ")\n",
    "\n",
    "print(f\"DINO parameters (total): {sum(p.numel() for p in dino_model.parameters()):,}\")\n",
    "print(f\"DINO parameters (trainable): {sum(p.numel() for p in dino_model.parameters() if p.requires_grad):,}\")\n",
    "\n",
    "# --- Train Stage 1: Frozen backbone ---\n",
    "wandb.init(project='facial-keypoints', name='dino-frozen', reinit=True)\n",
    "wandb.config.update({'model': 'dino', 'criterion': DINO_CRITERION, 'freeze': True})\n",
    "\n",
    "dino_epoch, dino_step = train_regression(\n",
    "    dino_model, dino_train_loader, dino_test_loader, dino_optimizer,\n",
    "    DINO_CRITERION, device, model_name='dino', num_epochs=DINO_EPOCHS_FROZEN\n",
    ")\n",
    "\n",
    "save_checkpoint(dino_model, dino_optimizer, dino_epoch, dino_step, 'dino',\n",
    "                path='checkpoints-dino/frozen_checkpoint.pth')\n",
    "wandb.finish()\n",
    "print(\"DINO Stage 1 (frozen backbone) complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7 Train DINO (Stage 2: Fine-tune Full Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "DINO_EPOCHS_FINETUNE = 50\n",
    "DINO_LR_FINETUNE = 1e-4\n",
    "\n",
    "# --- Unfreeze and set up new optimizer ---\n",
    "dino_model._unfreeze_backbone()\n",
    "dino_optimizer = torch.optim.Adam(dino_model.parameters(), lr=DINO_LR_FINETUNE)\n",
    "\n",
    "print(f\"DINO parameters (trainable after unfreeze): {sum(p.numel() for p in dino_model.parameters() if p.requires_grad):,}\")\n",
    "\n",
    "# --- Train Stage 2: Fine-tune ---\n",
    "wandb.init(project='facial-keypoints', name='dino-finetune', reinit=True)\n",
    "wandb.config.update({'model': 'dino', 'criterion': DINO_CRITERION, 'freeze': False})\n",
    "\n",
    "dino_epoch, dino_step = train_regression(\n",
    "    dino_model, dino_train_loader, dino_test_loader, dino_optimizer,\n",
    "    DINO_CRITERION, device, model_name='dino', num_epochs=DINO_EPOCHS_FINETUNE\n",
    ")\n",
    "\n",
    "save_checkpoint(dino_model, dino_optimizer, dino_epoch, dino_step, 'dino',\n",
    "                path='checkpoints-dino/last_checkpoint.pth')\n",
    "wandb.finish()\n",
    "print(\"DINO Stage 2 (fine-tune) complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8 Visualize DINO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_keypoints(dino_test_loader, dino_model, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. U-Net (Heatmap-based)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"Two consecutive conv-bn-relu blocks.\"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels=1, num_keypoints=68, heatmap_size=64):\n",
    "        super().__init__()\n",
    "        self.heatmap_size = heatmap_size\n",
    "\n",
    "        # Encoder\n",
    "        self.enc1 = DoubleConv(in_channels, 32)\n",
    "        self.enc2 = DoubleConv(32, 64)\n",
    "        self.enc3 = DoubleConv(64, 128)\n",
    "        self.enc4 = DoubleConv(128, 256)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.dropout_enc = nn.Dropout2d(p=0.3)\n",
    "\n",
    "        # Bottleneck\n",
    "        self.bottleneck = DoubleConv(256, 512)\n",
    "        self.dropout_bottleneck = nn.Dropout2d(p=0.3)\n",
    "        self.dropout_dec = nn.Dropout2d(p=0.2)\n",
    "\n",
    "        # Decoder\n",
    "        self.up4 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.dec4 = DoubleConv(512, 256)\n",
    "        self.up3 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.dec3 = DoubleConv(256, 128)\n",
    "        self.up2 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.dec2 = DoubleConv(128, 64)\n",
    "        self.up1 = nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2)\n",
    "        self.dec1 = DoubleConv(64, 32)\n",
    "\n",
    "        self.out_conv = nn.Conv2d(32, num_keypoints, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        e1 = self.enc1(x)\n",
    "        e2 = self.enc2(self.pool(e1))\n",
    "        e3 = self.enc3(self.pool(e2))\n",
    "        e4 = self.dropout_enc(self.enc4(self.pool(e3)))\n",
    "\n",
    "        b = self.dropout_bottleneck(self.bottleneck(self.pool(e4)))\n",
    "\n",
    "        d4 = self.dropout_dec(self.dec4(torch.cat([self.up4(b), e4], dim=1)))\n",
    "        d3 = self.dropout_dec(self.dec3(torch.cat([self.up3(d4), e3], dim=1)))\n",
    "        d2 = self.dec2(torch.cat([self.up2(d3), e2], dim=1))\n",
    "        d1 = self.dec1(torch.cat([self.up1(d2), e1], dim=1))\n",
    "\n",
    "        out = self.out_conv(d1)\n",
    "        out = F.interpolate(out, size=self.heatmap_size, mode='bilinear', align_corners=False)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Train U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "UNET_EPOCHS = 50\n",
    "UNET_LR = 1e-3\n",
    "UNET_BATCH_SIZE = 256\n",
    "\n",
    "# --- Initialize ---\n",
    "unet_model = UNet(in_channels=1, num_keypoints=68, heatmap_size=64).to(device)\n",
    "unet_train_loader, unet_test_loader = load_heatmap_data(batch_size=UNET_BATCH_SIZE)\n",
    "unet_optimizer = torch.optim.Adam(unet_model.parameters(), lr=UNET_LR, weight_decay=1e-5)\n",
    "\n",
    "print(f\"U-Net parameters: {sum(p.numel() for p in unet_model.parameters()):,}\")\n",
    "\n",
    "# --- Train ---\n",
    "wandb.init(project='facial-keypoints', name='unet-train', reinit=True)\n",
    "wandb.config.update({'model': 'unet', 'criterion': 'bce', 'lr': UNET_LR})\n",
    "\n",
    "unet_epoch, unet_step = train_heatmap(\n",
    "    unet_model, unet_train_loader, unet_test_loader, unet_optimizer,\n",
    "    device, model_name='unet', num_epochs=UNET_EPOCHS\n",
    ")\n",
    "\n",
    "save_checkpoint(unet_model, unet_optimizer, unet_epoch, unet_step, 'unet',\n",
    "                path='checkpoints-unet/last_checkpoint.pth')\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Visualize U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_keypoints(unet_test_loader, unet_model, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}